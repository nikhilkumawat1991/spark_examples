{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f516af51-1da6-461f-9227-8fe94cf99ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9d85828-a6e5-4947-ad6e-cb1a49bc3667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eecfd038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cgt_jpr_lin_nikhil/nikhil/spark/data/words.txt MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0\n",
      "2\n",
      "['A', 'wonderful', 'king', 'is', 'Hadoop.', 'The', 'elephant', 'plays', 'well', 'with', 'Sqoop.', 'But', 'what', 'helps', 'him', 'to', 'thrive', 'Are', 'Impala,', 'and', 'Hive,', 'And', 'HDFS', 'in', 'the', 'group', 'using', 'wonderful', 'king', '.']\n"
     ]
    }
   ],
   "source": [
    "sc = pyspark.SparkContext.getOrCreate()\n",
    "words = sc.textFile(\"/home/cgt_jpr_lin_nikhil/nikhil/spark/data/words.txt\")\n",
    "print(words)\n",
    "print(words.getNumPartitions())\n",
    "mapped_word = words.flatMap(lambda line: line.split(\" \"))\n",
    "print(mapped_word.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbe121cd-254a-487e-89b8-663c105cbd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 1), ('wonderful', 1), ('king', 1), ('is', 1), ('Hadoop.', 1), ('The', 1), ('elephant', 1), ('plays', 1), ('well', 1), ('with', 1), ('Sqoop.', 1), ('But', 1), ('what', 1), ('helps', 1), ('him', 1), ('to', 1), ('thrive', 1), ('Are', 1), ('Impala,', 1), ('and', 1), ('Hive,', 1), ('And', 1), ('HDFS', 1), ('in', 1), ('the', 1), ('group', 1), ('using', 1), ('wonderful', 1), ('king', 1), ('.', 1)]\n"
     ]
    }
   ],
   "source": [
    "ind = mapped_word.map(lambda word: (word,1))\n",
    "print(ind.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72ea1e77-5a3f-464b-b55f-9765b6285c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('wonderful', 2), ('king', 2), ('is', 1), ('Hadoop.', 1), ('The', 1), ('plays', 1), ('But', 1), ('Impala,', 1), ('Hive,', 1), ('And', 1), ('HDFS', 1), ('in', 1), ('group', 1), ('using', 1), ('.', 1), ('A', 1), ('elephant', 1), ('well', 1), ('with', 1), ('Sqoop.', 1), ('what', 1), ('helps', 1), ('him', 1), ('to', 1), ('thrive', 1), ('Are', 1), ('and', 1), ('the', 1)]\n"
     ]
    }
   ],
   "source": [
    "result = ind.reduceByKey(lambda a,b: a+b)\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b71ab32e-1350-4ae4-a3f7-4dacd4df8234",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.saveAsTextFile(\"/home/cgt_jpr_lin_nikhil/nikhil/spark/data/result.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ceead-a8fe-410f-929c-04aa2eb78de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
